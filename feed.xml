<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="https://giovannibriglia.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://giovannibriglia.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-03-28T17:07:27+00:00</updated><id>https://giovannibriglia.github.io/feed.xml</id><title type="html">blank</title><subtitle>I am Robotics Engineer graduated at the University of Modena and Reggio Emilia (IT). From November &apos;24 I am a PhD student at the University of Pisa. My focus comprehends Causality-Driven Reinforcement Learning. </subtitle><entry><title type="html">PRIMA 2024 - slides and proceeding</title><link href="https://giovannibriglia.github.io/blog/2024/prima-presentation-proceeding/" rel="alternate" type="text/html" title="PRIMA 2024 - slides and proceeding"/><published>2024-11-21T00:00:00+00:00</published><updated>2024-11-21T00:00:00+00:00</updated><id>https://giovannibriglia.github.io/blog/2024/prima-presentation-proceeding</id><content type="html" xml:base="https://giovannibriglia.github.io/blog/2024/prima-presentation-proceeding/"><![CDATA[<p>Today I had the privilege of presenting our paper, <em>“Improving Reinforcement Learning-Based Autonomous Agents with Causal Models,”</em> at PRIMA 2024 in Kyoto. You can access the slides I presented via this <a href="https://docs.google.com/presentation/d/e/2PACX-1vTDZUHQdq7vz76_2bpJQyv7qEs7iYSTHEL0j5rVM4-nWIytgcNoq7vLfv64DY4Qeg/pub?start=false&amp;loop=false&amp;delayms=60000">link</a>.</p> <p>Feel free to reach out if you’d like to connect or discuss further!</p> <p><a class="citation" href="#briglia2024improving">(Briglia et al., 2024)</a></p>]]></content><author><name></name></author><category term="research"/><category term="update"/><summary type="html"><![CDATA[Slides update and proceeding]]></summary></entry><entry><title type="html">Judea Pearl on Causal Models vs Probabilistic Models.</title><link href="https://giovannibriglia.github.io/blog/2024/causal-models/" rel="alternate" type="text/html" title="Judea Pearl on Causal Models vs Probabilistic Models."/><published>2024-11-08T00:00:00+00:00</published><updated>2024-11-08T00:00:00+00:00</updated><id>https://giovannibriglia.github.io/blog/2024/causal-models</id><content type="html" xml:base="https://giovannibriglia.github.io/blog/2024/causal-models/"><![CDATA[<p><a class="citation" href="#pearl2000models">(Pearl &amp; others, 2000)</a></p> <blockquote> <p>Causal models (assuming they are valid) are much more informative than probability models. A joint distribution tell us how probable events are and how probabilities would change with subsequent observations, but a causal model also tells us how those probabilities would change as a result of external interventions - such as those encountered in policy analysis, treatment management, or planning everyday activity. Such changes cannot be deduced from a joint distribution, even if fully specified.</p> <p>~Judea Pearl</p> </blockquote>]]></content><author><name></name></author><category term="research"/><category term="citation"/><summary type="html"><![CDATA[Comparing the Informativeness of Causal and Probabilistic Models"]]></summary></entry><entry><title type="html">Improving Reinforcement Learning Exploration with Causal Models</title><link href="https://giovannibriglia.github.io/blog/2024/paper-prima/" rel="alternate" type="text/html" title="Improving Reinforcement Learning Exploration with Causal Models"/><published>2024-09-25T00:00:00+00:00</published><updated>2024-09-25T00:00:00+00:00</updated><id>https://giovannibriglia.github.io/blog/2024/paper-prima</id><content type="html" xml:base="https://giovannibriglia.github.io/blog/2024/paper-prima/"><![CDATA[<h3 id="resume">Resume</h3> <p>In this work, we explore a novel way to enhance reinforcement learning (RL) in autonomous agents by integrating causal models into the learning process. We introduce the Causality-Driven Reinforcement Learning (CDRL) framework, it can improve exploration efficiency by leveraging causal discovery. Rather than requiring agents to explore all possible actions and states, CDRL learns a causal model from a simplified version of the environment. This model focuses on key transitions, such as actions that lead directly to success or failure, and then serves as a guide to navigate more complex environments. The two-phase approach—Causal Discovery (CD) and Causal RL (CRL)—allows for a faster and more efficient learning process.</p> <p>Using various RL algorithms, we demonstrate that CDRL consistently improves both the speed and effectiveness of learning in complex environments. Not only does it reduce the number of actions required to complete tasks, but it also generalizes well to previously unseen environments. The experiments show that CDRL can be implemented in both online and offline settings, with offline learning yielding particularly promising results, as the causal model can be trained once and reused in larger environments without degradation in performance.</p> <p>This approach offers a modular solution to enhance existing RL frameworks, making it adaptable and scalable for a wide range of applications in AI and autonomous systems.</p> <p><a href="https://github.com/Giovannibriglia/AgentGroup_CausalRL">Explore the Code and Results on GitHub</a></p> <hr/> <h3 id="environment-examples">Environment Examples</h3> <p>Below are examples of the environments considered:</p> <div class="row mt-3"> <div class="col-sm-6"> <figure> <picture> <img src="/assets/img/grid.gif" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm-6"> <figure> <picture> <img src="/assets/img/maze.gif" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <hr/> <h3 id="plot-extract">Plot Extract</h3> <p>Here is an extract from the results:</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <img src="/assets/img/prima_plot1.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <img src="/assets/img/prima_plot2.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <hr/>]]></content><author><name></name></author><category term="research"/><category term="concepts"/><category term="update"/><summary type="html"><![CDATA[New paper accepted at PRIMA 2024, Kyoto, 18-24 November]]></summary></entry><entry><title type="html">Aleksander Molak interviews Judea Pearl</title><link href="https://giovannibriglia.github.io/blog/2024/molak-pearl/" rel="alternate" type="text/html" title="Aleksander Molak interviews Judea Pearl"/><published>2024-08-26T00:00:00+00:00</published><updated>2024-08-26T00:00:00+00:00</updated><id>https://giovannibriglia.github.io/blog/2024/molak-pearl</id><content type="html" xml:base="https://giovannibriglia.github.io/blog/2024/molak-pearl/"><![CDATA[<p>In this blog post, we’re taking a closer look at the remarkable contributions of <a href="https://bayes.cs.ucla.edu/jp_home.html">Judea Pearl</a>, often regarded as the “godfather of the causality movement.” Specifically, I’ll focus on the interview he recently had with <a href="https://alxndr.io/">Aleksander Molak</a> on his <a href="https://causalbanditspodcast.com/">podcast</a>.</p> <p>After watching the <a href="https://www.youtube.com/watch?v=yqKJ9pUQ6Q8&amp;t=7s">interview</a>, I was deeply impressed. Given such a renowned figure in the field, my expectations were high, and I’m excited to say that they were more than met. The discussion is rich with thought-provoking ideas, seamlessly blending technical depth with accessible insights.</p> <p>In this post, I’ll share the key concepts that struck me and explain why this conversation is essential viewing for anyone interested in causality and beyond.</p> <hr/> <hr/> <h4 id="the-evolution-from-bayesian-networks-to-structural-causal-models-scms">The Evolution from Bayesian Networks to Structural Causal Models (SCMs)</h4> <p>Judea Pearl discussed the pivotal moment in his career when he transitioned from Bayesian networks to the formalism of Structural Causal Models (SCMs). This shift was marked by a focus on <strong>deterministic functions</strong>, which was initially a challenging concept after years of working within a probabilistic framework. Pearl and his collaborator, <strong>Thomas Verma</strong>, sought to formalize counterfactuals within this new framework, laying the foundation for much of modern causal inference.</p> <hr/> <h4 id="the-influence-of-early-education-and-the-legacy-of-great-teachers">The Influence of Early Education and the Legacy of Great Teachers</h4> <p>Pearl reflected on the significant impact his early education had on his career. Interestingly, he shared an anecdote about how both he and Daniel Kahneman, the Nobel laureate in economics, had the same influential teacher during their formative years. Pearl emphasized that such educators, who could engage with students on a wide range of topics without notes, were instrumental in shaping their intellectual curiosity and confidence. <strong>He lamented that such holistic and deeply knowledgeable teaching is rare today.</strong></p> <hr/> <h4 id="the-nature-of-human-reasoning-vs-ai-reasoning">The Nature of Human Reasoning vs. AI Reasoning</h4> <p>When discussing the differences between human reasoning and artificial intelligence, Pearl highlighted the <strong>shortcuts</strong> that humans take due to resource constraints—shortcuts that lead to biases and errors. In contrast, AI systems, particularly future general AI, may not suffer from these limitations due to their ability to process vast amounts of information more thoroughly. However, Pearl cautioned against speculating too much about how AI will evolve, given that we lack the metaphors and vocabulary to fully predict AI’s future behavior.</p> <hr/> <h4 id="causal-discovery-and-the-role-of-large-language-models-llms">Causal Discovery and the Role of Large Language Models (LLMs)</h4> <p>Pearl addressed the ongoing debate about the capabilities of Large Language Models (LLMs), particularly in their ability to learn causal relationships. He noted that while LLMs can learn from the causal models embedded in the text written by humans, <strong>this does not equate to learning causality from data alone</strong>. Pearl described the output of LLMs as a “salad of rumors”, a mixture of associations that, while potentially useful, lacks the rigorous structure of true causal reasoning. He also shared his cautious optimism that LLMs might eventually play a role in causal inference, especially when combined with causal models.</p> <hr/> <h4 id="the-future-of-research">The Future of Research</h4> <p>Pearl expressed his enthusiasm for the future of causal inference, particularly in the field of <strong>personalized medicine</strong>. He highlighted recent advancements in quantifying harm and benefit at an individual level, an area he believes will be crucial in various fields, including medicine, political science, and marketing. Pearl emphasized the need for researchers to focus on <strong>individualized decision-making</strong>, where specific situational factors are considered rather than relying solely on population-level data.</p> <hr/> <h4 id="the-divide-in-the-causal-inference-community">The Divide in the Causal Inference Community</h4> <p>Pearl acknowledged the rift between different traditions within the causal inference community, such as those who focus on graphical models and those rooted in potential outcomes. He pointed out that, despite the <strong>logical equivalence</strong> between these frameworks, the divide often stems from <strong>differing comfort levels in articulating assumptions</strong> in one language versus another. Pearl emphasized the need for a <strong>unified approach to causal inference</strong>, suggesting that many researchers already think in terms of <strong>graphs</strong>, even if they express their ideas differently for publication.</p> <hr/> <h4 id="the-role-of-education">The Role of Education</h4> <p>A recurring theme in Pearl’s conversation was the <strong>need for better education in causal inference</strong>. He argued that the limitations of randomized controlled trials (RCTs) and the broader implications of causal reasoning are not adequately covered in traditional statistics courses. Pearl stressed that understanding causality requires more than just knowledge of RCTs—it demands a grasp of complex concepts like necessary and sufficient causes, direct and indirect effects, and how these can be applied to real-world problems.</p> <hr/> <h4 id="reflections-on-life-and-advice-for-learners">Reflections on Life and Advice for Learners</h4> <p>Towards the end of the discussion, Pearl reflected on the importance of <strong>being part of a larger chain of knowledge and contributing to it</strong>, no matter how small the contribution may seem. He advised those starting out in complex fields to <strong>begin with manageable problems</strong> that they feel confident in mastering before expanding their scope. This approach, he suggested, not only makes learning more accessible but also allows for meaningful contributions to the field.</p> <hr/> <hr/> <p>In this post, I’ve summarized the key insights from this remarkable interview. However, I highly recommend watching the video to fully appreciate how Judea Pearl has transformed and continues to influence our way of thinking with a rare mix of humility and passion.</p> <p>A special thanks to Aleksander Molak for conducting this invaluable interview.</p> <p>I hope you find both the video and this summary insightful and inspiring.</p>]]></content><author><name></name></author><category term="research"/><category term="concepts"/><summary type="html"><![CDATA[Key concepts and recommendations for the causal community and beyond]]></summary></entry><entry><title type="html">Judea Pearl on planning under uncertainty</title><link href="https://giovannibriglia.github.io/blog/2024/planning-under-uncertainty-pearl/" rel="alternate" type="text/html" title="Judea Pearl on planning under uncertainty"/><published>2024-08-20T00:00:00+00:00</published><updated>2024-08-20T00:00:00+00:00</updated><id>https://giovannibriglia.github.io/blog/2024/planning-under-uncertainty-pearl</id><content type="html" xml:base="https://giovannibriglia.github.io/blog/2024/planning-under-uncertainty-pearl/"><![CDATA[<p><a class="citation" href="#pearl1994probabilistic">(Pearl, 1994)</a></p> <blockquote> <p>Probabilistic methods, especially those based on graphical models, have proven useful in tasks of prediction, abduction and belief revision.</p> <p>In planning, however, they are less popular, partly due to the unsettled, strange relationship between probability and actions. In principle, actions are not part of standard probability theory, and understandably so: probabilities capture normal relationships in the world, while actions represent interventions that perturb those relationships.</p> <p>~Judea Pearl</p> </blockquote>]]></content><author><name></name></author><category term="research"/><category term="citation"/><summary type="html"><![CDATA[A probabilistic calculus of actions]]></summary></entry><entry><title type="html">Career Update</title><link href="https://giovannibriglia.github.io/blog/2024/resume-and-phd-announcement/" rel="alternate" type="text/html" title="Career Update"/><published>2024-07-31T00:00:00+00:00</published><updated>2024-07-31T00:00:00+00:00</updated><id>https://giovannibriglia.github.io/blog/2024/resume-and-phd-announcement</id><content type="html" xml:base="https://giovannibriglia.github.io/blog/2024/resume-and-phd-announcement/"><![CDATA[<p>In the past year (2023), after coming back from Munich, where I completed an incredible exchange semester through the Erasmus+ program, I decided, also thanks to this experience, to pursue a PhD. Consequently, I applied to Politecnico di Milano, the University of Modena and Reggio Emilia, and the Italian National PhD in AI (based at the University of Pisa).</p> <p>To my surprise, I was accepted by all three institutions.</p> <p>In October 2023, I graduated from the University of Modena and Reggio Emilia with a degree in Mechatronics, Robotics, and Automation Engineering, achieving a score of 110 with laude. Despite this success, I felt disoriented. My experience at TUM in Munich left me with the impression that the most interesting opportunities were abroad, making me doubt if Italy was the right place for me. As a result, I decided to decline the positions in Italy and apply for some PhD abroad. I was rejected without even getting an interview from the ETH-AI Center, Max Planck Institute for Intelligent Systems, Munich Center for Machine Learning, Cyber Valley, ELLIS, EPFL, BMW, and relAI. Moreover, I was rejected from the University of Delft, for which, at least, I got an interview. Nevertheless, I won a PhD position at Eindhoven University and at the KIT lab, but I refused both offers, I was not so excited.</p> <p>Mostly in February, when most evaluations came in, I felt quite low. It’s not always easy to brush off disappointments, and I felt a bit adrift.</p> <p>Fortunately, since November, I have been working with Stefano Mariani and Franco Zambonelli, who welcomed me warmly into their research group. Together, we are exploring the intersection and the integration of model-free and model-based approaches, particularly focusing on reinforcement learning and causality.</p> <p>Over time, I’ve come to realize that while your environment undoubtedly influences you, the people you work with have an even greater impact. With this understanding, I am excited to collaborate with them.</p> <p>Additionally, I was given the opportunity to attend in-person the OxML “Representation Learning and Generative AI” program at the University of Oxford.</p> <p>Regarding my efforts to secure a PhD abroad, I was unsuccessful. However, this experience made me much stronger and more convinced of my goals. I realized that a rejection does not define a person’s abilities, and there are SIGNIFICANT factors influencing such decisions.</p> <p>I think I have found my way and I am meeting incredible people. They are the ones who feed my hunger for knowledge.</p> <p>Now, I am delighted to have been accepted into the National PhD program in AI, ranking first among all participants. Starting in November, I will be a PhD student and will continue working with Stefano Mariani and Franco Zambonelli. Additionally, I am seeking an engaging visiting research period during my PhD journey… (oh no, here we go again).</p>]]></content><author><name></name></author><category term="career"/><category term="update"/><summary type="html"><![CDATA[What is happened so far and PhD announcement]]></summary></entry></feed>